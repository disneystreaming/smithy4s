---
sidebar_label: Services and endpoints
title: Services and endpoints
---

In addition to relying heavily on a `Schema` construct that enables abstracting over serialisation, Smithy4s uses abstractions to codify the notion of interface to enable interoperability with various request/response protocols. The idea is to be able to reason generically about things that have shapes like :

```scala
trait Interface[Context[_]]{
  def operation1(a: A, b: B) : Context[Output1]
  def operation2(c: C, d: D, e: E) : Context[Output2]
}
```

in order to easily term implementations of such interfaces into services (http, rpc, etc), or, conversely, acquire instances of these high-level interfaces talking to remote services.

Creating an abstraction that allows to reason generically about such constructs is a problem similar to coming up with the `Schema` ADT : one needs to deconstruct it into fundamental building blocks.

## The duality of final and initial algebras

First things first, before we dive into the guts of the problem, one notion that is drastically helpful is the duality between finally-encoded algebras and initially-encoded algebras.

* Finally-encoded algebras are object-oriented encodings of a set of operations, just like above : operations are represented as **methods** in an interface. Interpretation of expressions written in terms of these methods does not involve any runtime transformation from one context to another : the method call is merely executed. In other words, when they are executed, expressions coming from finally-encoded algebras are already in their "final form".

* Conversely, initially-encoded algebras represent expressions as **data**, implying that interpretation involves a transformation of this data into lower level method calls. However, **data** has the quality of being a first class construct in programming languages, meaning you can pass it around and use it as parameter to functions. This allows for the unification of codepaths, as the differences between some aspects of a bit of logic can be absorbed by the data and handled later on.

Finally-encoded KVStore algebra :

```scala 
trait KVStore[Context[_]]{
  def put(key: String, value: String) : Context[Unit]
  def get(key: String)                : Context[Option[String]]
  def delete(key: String)             : Context[Unit]
}
```

Initially-encoded KVStore algebra :

```scala  
sealed trait KVStoreOp[Output]
object KVStoreOp {
  case class Put(key: String, value: String)  extends KVStore[Unit]
  case class Get(key: String)                 extends KVStore[Option[String]]
  case class Delete(key: String)              extends KVStore[Unit]
}
```

These two encodings contain a similar amount of information. It is even nearly-trivial to go from a `KVstore[Context]` instance to a `KVStoreOp ~> Context` natural transformation, and vice versa:

```scala
trait ~>[F[_], G[_]]{
  def apply[A](fa: F[A]) : G[A]
}

def asNaturalTransformation[Context[_]](impl: KVStore[Context]) = new (KVStoreOp ~> Context){
  def apply[A](fa: KVStoreOp[A]) : Context[A] = fa match {
    case KVStoreOp.Put(key, value) => impl.put(key, value)
    case KVStoreOp.Get(key)        => impl.get(key)
    case KVStoreOp.Delete(key)     => impl.delete(keyu)
  }
}

def fromNaturalTransformation[Context[_]](run: KVStoreOp ~> Context) = new KVStore[Context]{
  def put(key: String, value: String) = run(KVStoreOp.Put(key, value))
  def get(key: String)                = run(KVStoreOp.Get(key))
  def delete(key: String)             = run(KVStoreOp.Delete(key))
}
```

This duality is heavily used by smithy4s : finally-encoded interfaces are generally more natural to Scala developers, and are better supported in editors (autocompletion, etc). But from an implementation's perspective, the initial, data-base encoding is really interesting, because operations are reified as **datatypes** that can be associated with instances of generic typeclasses : it is possible to abstract over data, it is not possible to abstract over method calls.

### A detour around kinds

The methods generated by smith4s are conceptually similar to the methods expressed in the example above, except that the output types are way more verbose.

```scala
trait Interface[Context[_, _, _, _, _,]]{
  def operation1(a: A, b: B) : Context[Input, Error, Output, StreamedInput, StreamedOutput]
}
```

Let's address this awkwardness right away, by explaining the rationale behind this humongous signature :

#### Input

That's the input type of an operation. Typically, a case class that holds fields matching the method parameters. We keep track of it in the output type for several reasons:

* In the internal logic of Smithy4s, It prevents having to prematurely shoe-horn kinds into other kinds by means of injection/projection.
* It may very well come in handy for the implementation of some pagination-aware interpreters

#### Error

The execution of an operation can result in errors. The Smithy language allows for tying a list of errors to operations. When generating the associated code, Smithy4s synthetises a union so that the coproduct of errors associated to an operation are represented with a Scala type, which we can abstract over via some typeclass instance. This is also very useful for the writing of bifunctor interpreters, for users that are interested in this kind of UX.

#### Output

No surprise there : this is the data resulting from the run of the operation.

#### StreamedInput, StreamedOutput

Smithy supports the concept of [Streaming](https://awslabs.github.io/smithy/1.0/spec/core/stream-traits.html?highlight=streaming#streaming-trait). It is communicated as a trait that annotates a single field of the input shape or/and output shape of an operation. Scala does not have a "standard" way of expressing streaming semantics. Moreover, streaming constructs in Scala are heavily context dependant , so we could not possibly incorporate Streaming in our `Schema` construct which aims at being context-free and third-party-free. To get some intuition why that is : say we want to express streaming using [fs2](https://github.com/typelevel/fs2/). If we naively generate a case class that has one of its fields annotated with `@streaming`, it means that the the field is of type `fs2.Stream[F, A]`, which means that we either need to make a decision on what the `F` is, which is not okay for obvious reasons, or we need to propagate the `F[_]` type parameter upward to the case class. Now our `Schema` value, which accompanies the case-class, also have to carry the `F` ... this propagates throughout the whole codebase. We deemed that not acceptable.

Rather than polluting all layers of abstraction, we decided to just have the concept of operation be impacted and hold the streamed type in a separate type parameter. This allows for interpreters from various ecosystem to emerge. It also has the quality of allowing users to access the unary component of outputs (think, data that is communicated in the headers of http responses) without necessarily
allocating resources to consume the streamed component of outputs.

NB: at the time of writing this, smithy4s does not have any streaming-aware interpreter implemented. But streaming is such a fundamental notion in remote interaction that we had to devise a plan to ensure that third party could decide to implement interpreters without waiting.

### Transformation

Because of the complex kinds we're dealing with, we codify a natural-transformation, called `smithy4s.Transformation` that allows to work at this level :

```scala
trait Transformation[F[_, _, _, _, _], G[_, _, _, _, _]] {
  def apply[I, E, O, SI, SO](fa: F[I, E, O, SI, SO]): G[I, E, O, SI, SO]
}
```

This is a mouthful, but conceptually, it's exactly the same as our good old polymorphic `~>` function.

### Codifying the duality between initial and final algebras

What we want users to manipulate is the final-encoded version of a service: a good-old object-oriented interface that has decent good auto-completion in editors. But we need the inital-encoded version
to implement interpreters in a generic fashion.

So we codify the duality to allow for switching from one to the other via an abstraction called `smithy4s.Service`, which is the entry point to all interpreters.

```scala
trait Service[Final[_[_, _, _, _, _]], Initial[_, _, _, _, _]] {
  def asTransformation[F[_, _, _, _, _,]](alg: Final[F]) : Transformation[Initial, F]
  def transform[F[_, _, _, _, _]](transformation: Transformation[Initial, F])

  // ...
}
```

Implementations of such interfaces are code-generated. This implies that all smithy `Service` shapes get translated as a finally-encoded interface, but also as an intially-encoded `GADT`


## The high-level philosophy of smithy4s

The goal of Smithy4s is that allow users to derive stubs and services in various protocols, by running the generated code (or instances of generated interfaces) in some one-liner functions. To that end, Smithy4s surfaces a number of abstractions (such as `smithy4s.schemaSchema`) that allow for the implementation of (very) polymorphic interpreters that can operate on the generated code, which reflects what the user defines in their smithy Specs.

These abstractions contain all the elements that allow to intrepret a high-level method call (from an interface generated by Smithy4s) into a low level request, and then transform a low level response into the output of the method call, or vice versa.

### Logical flow: client-side

Conceptually, provided we want to derive a high-level client that uses some sort of `Request => Response` protocol,
the implementation would follow this sequence of steps:

1. Assuming this method call : `kvstore.get("key")`
2. turning the method call into a piece of data : `KVStoreOp.Get("key")` using the initially-encoded dual of the `KVStore` interface
3. Retrieving the smithy4s `Schemas` (input and output) associated to the `Get` operation
4. Compiling the schema associated to the input of the `Get` operation into some encoding function : `Get.Input => Request`
5. Running the request through a low-level `Request => Response` function (like an http client)
6. Running `Get` into some function that gives us its `Get.Input` representation
7. Compiling the schema associated to the output (`Get.Output` ~= `Option[String]`) of the `Get` operation into some decoding function `Response => Output`

So we get `kvstore.get => KVStoreOp.Get => Get.Input => Request => Response => Get.Output`, which gives us the full data flow, client side.

### Logical flow: server-side

The server side is different in that we want to derive the `Request => Response` function from an instance of our interface (`KVStore`). The goal is to
mechanically translate a request into a method call, and a method's output into a response. The sequence:

1. From a given `Request`, find the corresponding operation `Op` (for instance, by means of http path). Let's assume it's the `get` operation,
2. Retrieve the smithy4s `Schemas` (input and output) associated to the operation (`KVStoreOp.Get`)
3. Compile a `Request => Get.Input` decoding function, and run the `Request` through it
4. From `Get.Input`, recreate the `KVStoreOp.Get` instance
5. From `KVStoreOp.Get`, use the final-encoded dual of `KVStoreOp` to call the `KVStore#get` method (implemented by the user). This gets us an `Get.Output`
6. Compile a `Get.Output => Response` encoding function from the schemas, and run the output through it

So we get `Request => KVStoreOp.Get.Input => KVStoreOp.Get => kvstore.get => Get.Output => Response`, which gives us the full data flow, service side.
